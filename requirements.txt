datasets
transformers==4.48.0
sentencepiece
protobuf==3.20.3
torch
accelerate
einops
flash-attn
bottleneck>=1.3.6
